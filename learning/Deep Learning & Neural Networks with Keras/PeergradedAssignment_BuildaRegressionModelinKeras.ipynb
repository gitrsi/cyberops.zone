{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a4ba21d-8ddd-45aa-bb56-01fcca767cb8",
   "metadata": {},
   "source": [
    "<h1 align=center><font size = 5>Peer-graded Assignment: Build a Regression Model in Keras</font></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2bbeae-ba16-49b8-92d6-22b4046ed00d",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "This notebook covers the peer-graded assignment: \"Build a Regression Model in Keras\" which concludes the course \"Introduction to Deep Learning & Neural Networks with Keras\". "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7494bcc7-c644-453c-bd58-6a83275a944a",
   "metadata": {},
   "source": [
    "# Objectives\n",
    "## A. Build a baseline model\n",
    "Use the Keras library to build a neural network with the following:\n",
    "- One hidden layer of 10 nodes, and a ReLU activation function\n",
    "- Use the adam optimizer and the mean squared error  as the loss function.\n",
    "\n",
    "1. Randomly split the data into a training and test sets by holding 30% of the data for testing. You can use the train_test_split helper function from Scikit-learn.\n",
    "2. Train the model on the training data using 50 epochs.\n",
    "3. Evaluate the model on the test data and compute the mean squared error between the predicted concrete strength and the actual concrete strength. You can use the mean_squared_error function from Scikit-learn.\n",
    "4. Repeat steps 1 - 3, 50 times, i.e., create a list of 50 mean squared errors.\n",
    "5. Report the mean and the standard deviation of the mean squared errors.\n",
    "\n",
    "## B. Normalize the data\n",
    "Repeat Part A but use a normalized version of the data. Recall that one way to normalize the data is by subtracting the mean from the individual predictors and dividing by the standard deviation.\n",
    "\n",
    "How does the mean of the mean squared errors compare to that from Step A?\n",
    "\n",
    "## C. Increase the number of epochs\n",
    "Repeat Part B but use 100 epochs this time for training.\n",
    "How does the mean of the mean squared errors compare to that from Step B?\n",
    "\n",
    "## D. Increase the number of hidden layers\n",
    "Repeat part B but use a neural network with the following instead:\n",
    "- Three hidden layers, each of 10 nodes and ReLU activation function.\n",
    "\n",
    "How does the mean of the mean squared errors compare to that from Step B?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ecf3dd-64a5-4dc8-84c8-d2618a3a47a4",
   "metadata": {},
   "source": [
    "# Table of content"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ce263be0-c7f3-41e3-891c-45911503194f",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
    "\n",
    "<font size = 3>\n",
    "    \n",
    "1. <a href=\"#item31\">...</a>  \n",
    "2. <a href=\"#item32\">...</a>  \n",
    "\n",
    "\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcace52-f852-429f-a748-68e0d07fa953",
   "metadata": {},
   "source": [
    "# Concrete compressive strength regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb13ed29-32a7-4dd2-a570-0d6e155d620d",
   "metadata": {},
   "source": [
    "## Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed153a6a-8e16-469f-acb2-d48ed5b9dfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All Libraries required for this lab are listed below. The libraries pre-installed on Skills Network Labs are commented. \n",
    "# If you run this notebook on a different environment, e.g. your desktop, you may need to uncomment and install certain libraries.\n",
    "\n",
    "#!pip install numpy==1.21.4\n",
    "#!pip install pandas==1.3.4\n",
    "#!pip install keras==2.1.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa649a41-a285-4b4b-b91a-4bfb768291b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eaf378a-8a94-4fc5-bd83-610050288a69",
   "metadata": {},
   "source": [
    "## Load and prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f520e5c0-3c9f-49e8-9eca-35a87dc67175",
   "metadata": {},
   "source": [
    "### Get dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048c6257-db58-4fd5-8581-46aca9efd7a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get Data\n",
    "concrete_data = pd.read_csv('https://cocl.us/concrete_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586cd3a6-96f4-4e53-b90e-06181fca6aa8",
   "metadata": {},
   "source": [
    "### Data structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6126e829-3ddc-43ec-a4b0-861a51ede47d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data preview\n",
    "concrete_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379266fe-e611-4109-95cd-9e36954a5cf9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Datapoints\n",
    "concrete_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640fb005-3083-413e-9212-1d8ce39ddf64",
   "metadata": {},
   "source": [
    "The concrete dataset consists of 1030 rows with 9 columns.\n",
    "\n",
    "Predictors\n",
    "- Cement\n",
    "- Blast Furnace Slag\n",
    "- Fly Ash\n",
    "- Water\n",
    "- Superplasticizer\n",
    "- Coarse Aggregate\n",
    "- Fine Aggregate\n",
    "- Age\n",
    "\n",
    "Target\n",
    "- Strength"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ddeb54-a16d-4c21-befe-446bc992da24",
   "metadata": {},
   "source": [
    "### Check and cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d9107a-8d0d-44d2-8f0e-7485424819ec",
   "metadata": {},
   "source": [
    "#### Data Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445b8951-1c39-4b50-b22b-52a131173bc4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data statistics\n",
    "concrete_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add07a03-7810-4677-92b4-b9a9f56cf7b8",
   "metadata": {},
   "source": [
    "#### Check for null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cd1599-89fd-447e-a0d6-0d16ede03e97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# null values\n",
    "concrete_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1735e5-a792-40a3-aa9c-0294e3d3ea15",
   "metadata": {},
   "source": [
    "Data looks clean so far. The only thing we need to consider is not to overfit the model due to the low number of samples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0ef39e-6602-4415-8b0f-faa2a0280185",
   "metadata": {},
   "source": [
    "### Predictors and target split\n",
    "The target in this model is the strength. All other columns are predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f78c5a-b3b4-4fc5-9ea3-6814bceca956",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "concrete_data_columns = concrete_data.columns\n",
    "\n",
    "predictors = concrete_data[concrete_data_columns[concrete_data_columns != 'Strength']] # predictors\n",
    "target = concrete_data['Strength'] # target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d2540e-0155-4c78-b4f8-83cab9696f19",
   "metadata": {},
   "source": [
    "### Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadf9521-bf89-465d-9b55-0eb2dfcc582a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93385c6-1234-4ebc-8160-791d412ddc60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "target.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1756b7f-9ec1-449d-869c-35fb6fa2ce62",
   "metadata": {},
   "source": [
    "Preserve the number of predictor columns to n_cols for use as size of the input shape in the neural network layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab1c027-ca1b-400f-85bb-7b8469d8fcdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cols = predictors_norm.shape[1] # number of predictor columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d8300d-14e0-45c0-a737-edb3e42dbad5",
   "metadata": {},
   "source": [
    "## A. Build a baseline model\n",
    "Using the Keras library to build a neural network with the following:\n",
    "- One hidden layer of 10 nodes, and a ReLU activation function\n",
    "- Use the adam optimizer and the mean squared error as the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7923a9c-b447-4780-99bb-cab3e35bd274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define regression model\n",
    "def regression_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, activation='relu', input_shape=(n_cols,))) # One hidden layer of 10 nodes, and a ReLU activation function\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    # compile model\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error') # adam optimizer and the mean squared error  as the loss function\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92dd5c5b-79a3-4384-bf28-6ed7424c1ec3",
   "metadata": {},
   "source": [
    "### Train and test the model\n",
    "- Randomly split the data into a training and test sets by holding 30% of the data for testing using the __[train_test_split helper function from Scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)__.\n",
    "- Train the model on the training data using 50 epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06717a1e-2811-43dc-bc9d-01a91d54d6fd",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Build and train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720a56d3-6d7f-4470-b941-bc66965def20",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d9425e-fba9-49e9-8470-12e710bf31e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the model\n",
    "model = regression_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f877acf-594f-459d-b336-8a511e398332",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fde3f6-bca6-46cd-8508-2cf1fc4e9b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    predictors, target, test_size=0.3, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a696c9c-d80e-429a-b304-d17c53047ea0",
   "metadata": {},
   "source": [
    "##### Fit/train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e994cc-9c24-4437-bc6d-d54f6159b696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model\n",
    "# verbose is set to 0 for clarity, increase if needed\n",
    "model.fit(X_train, y_train, epochs=50, verbose=0) # train with training dataset and 50 epochs\n",
    "print(\"Training of model complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a4c2d1-c957-42c0-8b1e-0f52f33bbaca",
   "metadata": {},
   "source": [
    "##### Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf718c14-0130-4382-9f7f-6eaae8848b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = mean_squared_error(y_test, model.predict(X_test))\n",
    "print(\"The mean squared error (MSE) on test set: {:.4f}\".format(mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ad8c07-fc14-4110-a10a-b194831ee837",
   "metadata": {},
   "source": [
    "##### Repeat train and evaluation 50 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba73ab5b-4829-4008-8d15-adbf764a12d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate 50 times and calculate mean and standard deviation of the mean squared errors\n",
    "\n",
    "# mean squared errors\n",
    "mses_50 = np.array([])\n",
    "\n",
    "# build the model\n",
    "model_50 = regression_model()\n",
    "\n",
    "for i in range(50):\n",
    "    # train/test split\n",
    "    X_train_50, X_test_50, y_train_50, y_test_50 = train_test_split(\n",
    "        predictors, target, test_size=0.3, random_state=42\n",
    "    )\n",
    "\n",
    "    # fit the model\n",
    "    # verbose is set to 0 for clarity, increase if needed\n",
    "    model_50.fit(X_train_50, y_train_50, epochs=50, verbose=0) # train with training dataset and 50 epochs\n",
    "    # evaluate the model\n",
    "    mse_50 = mean_squared_error(y_test_50, model_50.predict(X_test_50))\n",
    "    mses_50 = np.append(mses_50, mse_50, axis=None)\n",
    "    print(\"Iteration \" + str(i) + \" of 50 training and evaluation of model complete. MSE is : {:.4f}\".format(mse_50))  \n",
    "    \n",
    "model_50_mse_mean = np.mean(mses_50, axis=0)\n",
    "model_50_mse_std = np.std(mses_50, axis=0)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"The mean deviation of the mean squared error (MSE) on regular test set: {:.4f}\".format(model_50_mse_mean))\n",
    "print(\"The standard deviation of the mean squared error (MSE) on regular test set: {:.4f}\".format(model_50_mse_std))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae0a476-5a53-4654-80c8-3bd527d1be31",
   "metadata": {},
   "source": [
    "## B. Normalize the data\n",
    "Repeat Part A but use a normalized version of the data. Recall that one way to normalize the data is by subtracting the mean from the individual predictors and dividing by the standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbb2ffe-1b5c-4bf4-a929-f3ee289dcb91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "predictors_norm = (predictors - predictors.mean()) / predictors.std()\n",
    "predictors_norm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ca582a-f04c-4b18-88b9-0295bda5bce7",
   "metadata": {},
   "source": [
    "### Train and evaluation 50 times with normalized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9114d3-06ed-41bb-a6bc-891f6c1c483a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# build the model\n",
    "model_50_norm = regression_model()\n",
    "\n",
    "# Train and evaluate 50 times and calculate mean and standard deviation of the mean squared errors\n",
    "\n",
    "# mean squared errors\n",
    "mses_50_norm = np.array([])\n",
    "\n",
    "for i in range(50):\n",
    "    # train/test split\n",
    "    X_train_50_norm, X_test_50_norm, y_train_50, y_test_50 = train_test_split(\n",
    "        predictors_norm, target, test_size=0.3, random_state=42\n",
    "    )\n",
    "\n",
    "    # fit the model\n",
    "    # verbose is set to 0 for clarity, increase if needed\n",
    "    model_50_norm.fit(X_train_50_norm, y_train_50, epochs=50, verbose=0) # train with normalized training dataset and 50 epochs\n",
    "    # evaluate the model\n",
    "    mse_50_norm = mean_squared_error(y_test_50, model_50_norm.predict(X_test_50_norm))\n",
    "    mses_50_norm = np.append(mses_50_norm, mse_50_norm, axis=None)\n",
    "    print(\"Iteration \" + str(i) + \" of 50 training and evaluation of model complete. MSE is : {:.4f}\".format(mse_50_norm))  \n",
    "\n",
    "model_50_norm_mse_mean = np.mean(mses_50_norm, axis=0)\n",
    "model_50_norm_mse_std = np.std(mses_50_norm, axis=0)\n",
    "    \n",
    "print(\"\\n\")\n",
    "print(\"The mean deviation of the mean squared error (MSE) on normalized test set: {:.4f}\".format(model_50_norm_mse_mean))\n",
    "print(\"The standard deviation of the mean squared error (MSE) on normalized test set: {:.4f}\".format(model_50_norm_mse_std))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b57ebf4-6576-4269-9132-315ef678b71a",
   "metadata": {},
   "source": [
    "#### Compare the mean of the mean squared errors between A and B\n",
    "> The mean deviation of the mean squared error (MSE) on regular test set: {{model_50_mse_mean}}\n",
    "\n",
    "> The mean deviation of the mean squared error (MSE) on normalized test set: {{model_50_norm_mse_mean}}\n",
    "\n",
    "\n",
    "When comparing A and B we observe the following\n",
    "- the mean of the mean squared errors with normalized data in B is lower then in A (regular data)\n",
    "- generally the mean squared errors decrease with more training iterations\n",
    "- While the decrease of MSE in B looks continuous and smooth, the decrease in A shows some outliers\n",
    "\n",
    "This means that with normalized data we observe more accurate predictions.\n",
    "\n",
    "As we know some machine learning algorithms benefit from normalization, e.g. KNN, Logistic Regression, K-Means and Neural Networks. \n",
    "That agrees with our above observations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4eda9d-5a50-454c-baf3-74e2217ceb11",
   "metadata": {},
   "source": [
    "#### Compare the decrease of mean squared errors between regular and normalized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7520fe55-9f42-4965-80b5-d8f11dbedf9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plott MSE for regular vs. normalized data\n",
    "\n",
    "regular_MSEs = mses_50\n",
    "normalized_MSEs = mses_50_norm\n",
    "iterations = np.arange(50)\n",
    "\n",
    "plt.title(\"Mean squared error (MSE) on regular vs. normalized data \")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Mean squared error (MSE)\")\n",
    "\n",
    "plt.scatter(iterations, regular_MSEs, color=\"orange\",)\n",
    "plt.scatter(iterations, normalized_MSEs, color=\"green\",)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b5ae47-02f9-4ae6-ba70-a3bdeab10bd8",
   "metadata": {},
   "source": [
    "## C. Increase the number of epochs\n",
    "Repeat Part B but use 100 epochs this time for training. How does the mean of the mean squared errors compare to that from Step B?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6bf627-ee54-4672-a059-f783cf86d61c",
   "metadata": {},
   "source": [
    "### Train and evaluation 50 times with 100 epochs each on normalized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7ec548-9859-4134-a971-4a2549c8d090",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# build the model\n",
    "model_100_norm = regression_model()\n",
    "\n",
    "# Train and evaluate 50 times and calculate mean and standard deviation of the mean squared errors\n",
    "\n",
    "# mean squared errors\n",
    "mses_100_norm = np.array([])\n",
    "\n",
    "for i in range(50):\n",
    "    # train/test split\n",
    "    X_train_100_norm, X_test_100_norm, y_train_100, y_test_100 = train_test_split(\n",
    "        predictors_norm, target, test_size=0.3, random_state=42\n",
    "    )\n",
    "\n",
    "    # fit the model\n",
    "    # verbose is set to 0 for clarity, increase if needed\n",
    "    model_100_norm.fit(X_train_100_norm, y_train_100, epochs=100, verbose=0) # train with normalized training dataset and 50 epochs\n",
    "    # evaluate the model\n",
    "    mse_100_norm = mean_squared_error(y_test_100, model_100_norm.predict(X_test_100_norm))\n",
    "    mses_100_norm = np.append(mses_100_norm, mse_100_norm, axis=None)\n",
    "    print(\"Iteration \" + str(i) + \" of 50 training and evaluation of model complete. MSE is : {:.4f}\".format(mse_100_norm))  \n",
    "\n",
    "model_100_norm_mse_mean = np.mean(mses_50_norm, axis=0)\n",
    "model_100_norm_mse_std = np.std(mses_50_norm, axis=0)\n",
    "    \n",
    "print(\"\\n\")\n",
    "print(\"The mean deviation of the mean squared error (MSE) on normalized test set with 100 epochs: {:.4f}\".format(model_100_norm_mse_mean))\n",
    "print(\"The standard deviation of the mean squared error (MSE) on normalized test set with 100 epochs: {:.4f}\".format(model_100_norm_mse_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a02fbd3-b03b-4fa6-b407-263c24bdafe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Compare the mean of the mean squared errors between B and C\n",
    "> The mean deviation of the mean squared error (MSE) on normalized test set: {{model_50_norm_mse_mean}}\n",
    "\n",
    "> \n",
    "\n",
    "After x iterations \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f19367-e04f-401f-a6a7-27d3b3c1fe07",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plott MSE for 50 vs. 100 epoch training\n",
    "\n",
    "epoch_50_MSEs = mses_50_norm\n",
    "epoch_100_MSEs = mses_100_norm\n",
    "iterations = np.arange(50)\n",
    "\n",
    "plt.title(\"Mean squared error (MSE) on regular vs. normalized data \")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Mean squared error (MSE)\")\n",
    "\n",
    "plt.scatter(iterations, epoch_50_MSEs, color=\"orange\",)\n",
    "plt.scatter(iterations, epoch_100_MSEs, color=\"green\",)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d87f78-209f-4d1c-82a7-dc5470726136",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
