{"cells":[{"cell_type":"markdown","id":"f211579a-dca0-4055-add2-26837f21eb86","metadata":{},"outputs":[],"source":["\u003cp style=\"text-align:center\"\u003e\n","    \u003ca href=\"https://skills.network\" target=\"_blank\"\u003e\n","    \u003cimg src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"\u003e\n","    \u003c/a\u003e\n","\u003c/p\u003e\n"]},{"cell_type":"markdown","id":"5d31ac56-db14-42f3-accd-76e1ff2aac04","metadata":{},"outputs":[],"source":["\u003ch1\u003eTest Uniform, Default and Xavier Uniform Initialization on MNIST dataset with tanh activation\u003c/h1\u003e\n"]},{"cell_type":"markdown","id":"6ab695dd-bfa6-43b7-8865-689d3c53af9d","metadata":{},"outputs":[],"source":["\n","\u003ch3\u003eObjective for this Notebook\u003ch3\u003e    \n","\u003ch5\u003e 1. Define Several Neural Network, Criterion function, Optimizer\u003c/h5\u003e\n","\u003ch5\u003e 2. Test Uniform, Default and Xavier Initialization \u003c/h5\u003e     \n","\n"]},{"cell_type":"markdown","id":"e242f39e-2fa3-4b26-9cc9-82c1a0c80fbc","metadata":{},"outputs":[],"source":["\u003ch2\u003eTable of Contents\u003c/h2\u003e\n","In this lab, you will test PyTroch Default Initialization, Xavier Initialization and Uniform Initialization on the MNIST dataset. \n","\n","\u003cul\u003e\n","    \u003cli\u003e\u003ca href=\"#Model\"\u003eNeural Network Module and Training Function\u003c/a\u003e\u003c/li\u003e\n","    \u003cli\u003e\u003ca href=\"#Make\"\u003eMake Some Data\u003c/a\u003e\u003c/li\u003e\n","    \u003cli\u003e\u003ca href=\"#Cost\"\u003eDefine Several Neural Network, Criterion function, Optimizer\u003c/a\u003e\u003c/li\u003e\n","    \u003cli\u003e\u003ca href=\"#Train\"\u003eTest Uniform, Default and Xavier Initialization\u003c/a\u003e\u003c/li\u003e\n","    \u003cli\u003e\u003ca href=\"#Result\"\u003eAnalyze Results\u003c/a\u003e\u003c/li\u003e\n","\u003c/ul\u003e\n","\n","\u003cp\u003eEstimated Time Needed: \u003cstrong\u003e25 min\u003c/strong\u003e\u003c/p\u003e\n","\n","\u003chr\u003e\n"]},{"cell_type":"markdown","id":"e3218828-1a43-414d-9af6-38b89b92aa79","metadata":{},"outputs":[],"source":["\u003ch2\u003ePreparation\u003c/h2\u003e\n"]},{"cell_type":"markdown","id":"aa908013-f126-41c7-9cda-6e029211c4d0","metadata":{},"outputs":[],"source":["We'll need the following libraries:  \n"]},{"cell_type":"code","id":"527cd298-079c-441f-921d-5da8b83070e3","metadata":{},"outputs":[],"source":["# Import the libraries we need to use in this lab\n\n# Using the following line code to install the torchvision library\n# !mamba install -y torchvision\n\nimport torch \nimport torch.nn as nn\nimport torchvision.transforms as transforms\nimport torchvision.datasets as dsets\nimport matplotlib.pylab as plt\nimport numpy as np\n\ntorch.manual_seed(0)"]},{"cell_type":"markdown","id":"701a7bc9-434a-4cfe-8dae-980e414b35d3","metadata":{},"outputs":[],"source":["\u003c!--Empty Space for separating topics--\u003e\n"]},{"cell_type":"markdown","id":"6f684e8c-0584-417c-a772-16bbfd899958","metadata":{},"outputs":[],"source":["\u003ch2 id=\"Model\"\u003eNeural Network Module and Training Function\u003c/h2\u003e \n"]},{"cell_type":"markdown","id":"72eb6d27-97f9-4ff5-b0ad-7798eb42cac7","metadata":{},"outputs":[],"source":["Define the neural network module or class with Xavier Initialization\n"]},{"cell_type":"code","id":"53b93f03-d102-446c-b541-7125291e6848","metadata":{},"outputs":[],"source":["# Define the neural network with Xavier initialization\n\nclass Net_Xavier(nn.Module):\n    \n    # Constructor\n    def __init__(self, Layers):\n        super(Net_Xavier, self).__init__()\n        self.hidden = nn.ModuleList()\n\n        for input_size, output_size in zip(Layers, Layers[1:]):\n            linear = nn.Linear(input_size, output_size)\n            torch.nn.init.xavier_uniform_(linear.weight)\n            self.hidden.append(linear)\n    \n    # Prediction\n    def forward(self, x):\n        L = len(self.hidden)\n        for (l, linear_transform) in zip(range(L), self.hidden):\n            if l \u003c L - 1:\n                x = torch.tanh(linear_transform(x))\n            else:\n                x = linear_transform(x)\n        return x"]},{"cell_type":"markdown","id":"04c00be5-54a6-4fdf-84d3-71f723f4e2e5","metadata":{},"outputs":[],"source":["Define the neural network module with Uniform Initialization:\n"]},{"cell_type":"code","id":"fa4fdff1-ae98-42fa-8523-84e301ff4c30","metadata":{},"outputs":[],"source":["# Define the neural network with Uniform initialization\n\nclass Net_Uniform(nn.Module):\n    \n    # Constructor\n    def __init__(self, Layers):\n        super(Net_Uniform, self).__init__()\n        self.hidden = nn.ModuleList()\n\n        for input_size, output_size in zip(Layers, Layers[1:]):\n            linear = nn.Linear(input_size, output_size)\n            linear.weight.data.uniform_(0, 1)\n            self.hidden.append(linear)\n    \n    # Prediction\n    def forward(self, x):\n        L = len(self.hidden)\n        for (l, linear_transform) in zip(range(L), self.hidden):\n            if l \u003c L - 1:\n                x = torch.tanh(linear_transform(x))\n            else:\n                x = linear_transform(x)\n        return x"]},{"cell_type":"markdown","id":"740ab3d1-dd41-4894-9a2e-ff59f86668c3","metadata":{},"outputs":[],"source":["Define the neural network module with PyTroch Default Initialization\n"]},{"cell_type":"code","id":"252e1fa4-baf5-4bc4-a1ec-5ca0d2eb348e","metadata":{},"outputs":[],"source":["# Define the neural network with Default initialization\n\nclass Net(nn.Module):\n    \n    # Constructor\n    def __init__(self, Layers):\n        super(Net, self).__init__()\n        self.hidden = nn.ModuleList()\n\n        for input_size, output_size in zip(Layers, Layers[1:]):\n            linear = nn.Linear(input_size, output_size)\n            self.hidden.append(linear)\n    \n    # Prediction\n    def forward(self, x):\n        L = len(self.hidden)\n        for (l, linear_transform) in zip(range(L), self.hidden):\n            if l \u003c L - 1:\n                x = torch.tanh(linear_transform(x))\n            else:\n                x = linear_transform(x)\n        return x"]},{"cell_type":"markdown","id":"ffd7e02e-dd37-4a84-be84-024e4866b734","metadata":{},"outputs":[],"source":["Define a function to train the model, in this case the function returns a Python dictionary to store the training loss and accuracy on the validation data \n"]},{"cell_type":"code","id":"1a6693be-3c7a-4ba0-ab45-6a1186ce023e","metadata":{},"outputs":[],"source":["# function to Train the model\n\ndef train(model, criterion, train_loader, validation_loader, optimizer, epochs = 100):\n    i = 0\n    loss_accuracy = {'training_loss':[], 'validation_accuracy':[]}  \n    \n    for epoch in range(epochs):\n        for i,(x, y) in enumerate(train_loader):\n            optimizer.zero_grad()\n            z = model(x.view(-1, 28 * 28))\n            loss = criterion(z, y)\n            loss.backward()\n            optimizer.step()\n            loss_accuracy['training_loss'].append(loss.data.item())\n            \n        correct = 0\n        for x, y in validation_loader:\n            yhat = model(x.view(-1, 28 * 28))\n            _, label = torch.max(yhat, 1)\n            correct += (label==y).sum().item()\n        accuracy = 100 * (correct / len(validation_dataset))\n        loss_accuracy['validation_accuracy'].append(accuracy)\n        \n    return loss_accuracy"]},{"cell_type":"markdown","id":"371fa1ca-f13b-4b26-b48f-34ecb6261a07","metadata":{},"outputs":[],"source":["\u003c!--Empty Space for separating topics--\u003e\n"]},{"cell_type":"markdown","id":"6334d4ce-7601-4df2-b249-38ecb39fd808","metadata":{},"outputs":[],"source":["\u003ch2 id=\"Makeup_Data\"\u003eMake Some Data\u003c/h2\u003e \n"]},{"cell_type":"markdown","id":"42a3caab-3f74-47d3-89a9-4751a072969a","metadata":{},"outputs":[],"source":["Load the training dataset by setting the parameters \u003ccode\u003etrain \u003c/code\u003e to \u003ccode\u003eTrue\u003c/code\u003e and convert it to a tensor  by placing a transform object int the argument \u003ccode\u003etransform\u003c/code\u003e\n"]},{"cell_type":"code","id":"9cc3046d-e72d-4fca-ba45-76ed90d225a4","metadata":{},"outputs":[],"source":["# Create the train dataset\n\ntrain_dataset = dsets.MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())"]},{"cell_type":"markdown","id":"2e6b9a72-fd61-4d57-ae34-f18784fd04f9","metadata":{},"outputs":[],"source":["Load the testing dataset by setting the parameters \u003ccode\u003etrain\u003c/code\u003e to \u003ccode\u003eFalse\u003c/code\u003e and convert it to a tensor  by placing a transform object int the argument \u003ccode\u003etransform\u003c/code\u003e\n"]},{"cell_type":"code","id":"3b7e8144-503e-4c0d-8d31-706f91355a94","metadata":{},"outputs":[],"source":["# Create the validation dataset\n\nvalidation_dataset = dsets.MNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())"]},{"cell_type":"markdown","id":"1b5f491d-068a-4f11-b9d8-5ea0a3ddc85f","metadata":{},"outputs":[],"source":["Create the training-data loader and the validation-data loader object \n"]},{"cell_type":"code","id":"65184679-e9fc-4b86-8a1d-c6a068963b4d","metadata":{},"outputs":[],"source":["# Create Dataloader for both train dataset and validation dataset\n\ntrain_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=2000, shuffle=True)\nvalidation_loader = torch.utils.data.DataLoader(dataset=validation_dataset, batch_size=5000, shuffle=False)"]},{"cell_type":"markdown","id":"032f6cbd-3efb-487f-8032-b7e3d40299ff","metadata":{},"outputs":[],"source":["\u003c!--Empty Space for separating topics--\u003e\n"]},{"cell_type":"markdown","id":"8ec67de0-6c4c-4720-813b-25d43f2ec56c","metadata":{},"outputs":[],"source":["\u003ch2 id=\"Cost\"\u003eDefine Neural Network, Criterion function, Optimizer and Train the Model\u003c/h2\u003e \n"]},{"cell_type":"markdown","id":"0f958b58-5acd-4cd5-b1f0-2a7257e78d7a","metadata":{},"outputs":[],"source":["Create the criterion function\n"]},{"cell_type":"code","id":"fd20f346-44c5-4b01-98de-554f6a477d01","metadata":{},"outputs":[],"source":["# Define criterion function\n\ncriterion = nn.CrossEntropyLoss()"]},{"cell_type":"markdown","id":"4fad7e21-653d-48c6-a7f5-d8754babfe65","metadata":{},"outputs":[],"source":["Create the model with 100 hidden layers  \n"]},{"cell_type":"code","id":"60a41abe-ce79-4e6b-864b-5e3b9d3980dd","metadata":{},"outputs":[],"source":["# Set the parameters\n\ninput_dim = 28 * 28\noutput_dim = 10\nlayers = [input_dim, 100, 10, 100, 10, 100, output_dim]\nepochs = 15"]},{"cell_type":"markdown","id":"21a24726-94c8-4fcd-83ca-4f928baf8343","metadata":{},"outputs":[],"source":["\u003c!--Empty Space for separating topics--\u003e\n"]},{"cell_type":"markdown","id":"e1b5e299-80df-4612-8c68-ed8261419756","metadata":{},"outputs":[],"source":["\u003ch2 id=\"Train\"\u003eTest PyTorch Default Initialization, Xavier Initialization, Uniform Initialization\u003c/h2\u003e \n"]},{"cell_type":"markdown","id":"b2b9b9b4-54de-433e-95cf-4e4e8586a8d6","metadata":{},"outputs":[],"source":["Train the network using PyTorch Default Initialization\n"]},{"cell_type":"code","id":"6d941fab-4fca-4c80-8860-e1fc5401efcd","metadata":{},"outputs":[],"source":["# Train the model with default initialization\n\nmodel = Net(layers)\nlearning_rate = 0.01\noptimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\ntraining_results = train(model, criterion, train_loader, validation_loader, optimizer, epochs=epochs)"]},{"cell_type":"markdown","id":"59263979-ec3f-496c-a112-b06d33eeff6c","metadata":{},"outputs":[],"source":["Train the network using Xavier Initialization function\n"]},{"cell_type":"code","id":"4033cb41-5fe9-47bb-b2ef-04d7d1177cc6","metadata":{},"outputs":[],"source":["# Train the model with Xavier initialization\n\nmodel_Xavier = Net_Xavier(layers)\noptimizer = torch.optim.SGD(model_Xavier.parameters(), lr=learning_rate)\ntraining_results_Xavier = train(model_Xavier, criterion, train_loader, validation_loader, optimizer, epochs=epochs)"]},{"cell_type":"markdown","id":"0867dc68-11f7-4b45-808d-808d5b173771","metadata":{},"outputs":[],"source":["Train the network using Uniform Initialization\n"]},{"cell_type":"code","id":"9e91cd5d-efe4-4dc4-b8b9-449705678f38","metadata":{},"outputs":[],"source":["# Train the model with Uniform initialization\n\nmodel_Uniform = Net_Uniform(layers)\noptimizer = torch.optim.SGD(model_Uniform.parameters(), lr=learning_rate)\ntraining_results_Uniform = train(model_Uniform, criterion, train_loader, validation_loader, optimizer, epochs=epochs)"]},{"cell_type":"markdown","id":"c14eb8b1-e638-44ca-95e3-64aa12b67683","metadata":{},"outputs":[],"source":["\u003c!--Empty Space for separating topics--\u003e\n"]},{"cell_type":"markdown","id":"5398f093-155c-4568-bf50-a45a0b5a4b12","metadata":{},"outputs":[],"source":["\u003ch2 id=\"Result\"\u003eAnalyse Results\u003c/h2\u003e \n"]},{"cell_type":"markdown","id":"432a6e59-5c38-45bd-aed5-6cb1f75e4073","metadata":{},"outputs":[],"source":["Compare the training loss for each initialization\n"]},{"cell_type":"code","id":"75e9c2c9-0084-42fd-acae-cada477c3a38","metadata":{},"outputs":[],"source":["# Plot the loss\n\nplt.plot(training_results_Xavier['training_loss'], label='Xavier')\nplt.plot(training_results['training_loss'], label='Default')\nplt.plot(training_results_Uniform['training_loss'], label='Uniform')\nplt.ylabel('loss')\nplt.xlabel('iteration ')  \nplt.title('training loss iterations')\nplt.legend()"]},{"cell_type":"markdown","id":"b3795d51-22ae-4fa5-9c08-77e78f53aa93","metadata":{},"outputs":[],"source":["compare the validation loss for each model  \n"]},{"cell_type":"code","id":"810f1284-524a-4714-bba1-7d10cd216c8a","metadata":{},"outputs":[],"source":["# Plot the accuracy\n\nplt.plot(training_results_Xavier['validation_accuracy'], label='Xavier')\nplt.plot(training_results['validation_accuracy'], label='Default')\nplt.plot(training_results_Uniform['validation_accuracy'], label='Uniform') \nplt.ylabel('validation accuracy')\nplt.xlabel('epochs')   \nplt.legend()"]},{"cell_type":"markdown","id":"26fb8568-9d63-4d62-9bf6-14dd051f854b","metadata":{},"outputs":[],"source":["\n","\u003ca href=\"https://dataplatform.cloud.ibm.com/registration/stepone?utm_source=skills_network\u0026utm_content=in_lab_content_link\u0026utm_id=Lab-IBMDeveloperSkillsNetwork-DL0110EN-SkillsNetwork\u0026context=cpdaas\u0026apps=data_science_experience%2Cwatson_machine_learning\"\u003e\u003cimg src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DL0110EN-SkillsNetwork/Template/module%201/images/Watson_Studio.png\"\u003e\u003c/a\u003e\n"]},{"cell_type":"markdown","id":"33238d92-91d4-4ed9-9000-18b046ec6bf6","metadata":{},"outputs":[],"source":["\u003c!--Empty Space for separating topics--\u003e\n"]},{"cell_type":"markdown","id":"744dc556-d6aa-4a70-ad0b-474acf614cd2","metadata":{},"outputs":[],"source":["\u003ch2\u003eAbout the Authors:\u003c/h2\u003e \n","\n","\u003ca href=\"https://www.linkedin.com/in/joseph-s-50398b136/\"\u003eJoseph Santarcangelo\u003c/a\u003e has a PhD in Electrical Engineering, his research focused on using machine learning, signal processing, and computer vision to determine how videos impact human cognition. Joseph has been working for IBM since he completed his PhD. \n"]},{"cell_type":"markdown","id":"90f7c116-e24b-4cfd-ad24-fa7a696d6169","metadata":{},"outputs":[],"source":["Other contributors: \u003ca href=\"https://www.linkedin.com/in/michelleccarey/\"\u003eMichelle Carey\u003c/a\u003e, \u003ca href=\"www.linkedin.com/in/jiahui-mavis-zhou-a4537814a\"\u003eMavis Zhou\u003c/a\u003e\n"]},{"cell_type":"markdown","id":"22a1d973-ec9b-408c-b02a-fe3cefb4c9e0","metadata":{},"outputs":[],"source":["\u003c!--\n","## Change Log\n","\n","|  Date (YYYY-MM-DD) |  Version | Changed By  |  Change Description |\n","|---|---|---|---|\n","| 2020-09-23  | 2.0  | Srishti  |  Migrated Lab to Markdown and added to course repo in GitLab |\n","\n","\n","\n","\u003chr\u003e\n","--\u003e\n","\n","## \u003ch3 align=\"center\"\u003e \u0026#169; IBM Corporation. All rights reserved. \u003ch3/\u003e\n"]}],"metadata":{"kernelspec":{"display_name":"Python","language":"python","name":"conda-env-python-py"},"language_info":{"name":""}},"nbformat":4,"nbformat_minor":4}