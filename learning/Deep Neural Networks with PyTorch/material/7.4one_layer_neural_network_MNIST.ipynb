{"cells":[{"cell_type":"markdown","id":"4741634a-caba-4a67-b17f-7851c88e1580","metadata":{},"outputs":[],"source":["\u003cp style=\"text-align:center\"\u003e\n","    \u003ca href=\"https://skills.network\" target=\"_blank\"\u003e\n","    \u003cimg src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"\u003e\n","    \u003c/a\u003e\n","\u003c/p\u003e\n"]},{"cell_type":"markdown","id":"4ad59952-726b-47c9-9445-3d52f0ef0379","metadata":{},"outputs":[],"source":["\u003ch1\u003eNeural Networks with One Hidden Layer\u003c/h1\u003e\n"]},{"cell_type":"markdown","id":"20b3a24b-42c5-4d0c-9192-6f0ab59755f5","metadata":{},"outputs":[],"source":["\u003ch2\u003eObjective\u003c/h2\u003e\u003cul\u003e\u003cli\u003e How to classify handwritten digits using Neural Network.\u003c/li\u003e\u003c/ul\u003e \n"]},{"cell_type":"markdown","id":"aa8f1975-a877-4249-9e85-2cb69a638daa","metadata":{},"outputs":[],"source":["\u003ch2\u003eTable of Contents\u003c/h2\u003e\n","\u003cp\u003eIn this lab, you will use a single layer neural network to classify handwritten digits from the MNIST database.\u003c/p\u003e\n","\n","\u003cul\u003e\n","    \u003cli\u003e\u003ca href=\"#Model\"\u003eNeural Network Module and Training Function\u003c/a\u003e\u003c/li\u003e\n","    \u003cli\u003e\u003ca href=\"#Makeup_Data\"\u003eMake Some Data\u003c/a\u003e\u003c/li\u003e\n","    \u003cli\u003e\u003ca href=\"#Train\"\u003eDefine the Neural Network, Optimizer, and Train the  Model\u003c/a\u003e\u003c/li\u003e\n","    \u003cli\u003e\u003ca href=\"#Result\"\u003eAnalyze Results\u003c/a\u003e\u003c/li\u003e\n","\u003c/ul\u003e\n","\u003cp\u003eEstimated Time Needed: \u003cstrong\u003e25 min\u003c/strong\u003e\u003c/p\u003e\n","\n","\u003chr\u003e\n"]},{"cell_type":"markdown","id":"bc88f8f7-c11a-4261-997b-23413373a846","metadata":{},"outputs":[],"source":["\u003ch2\u003ePreparation\u003c/h2\u003e\n"]},{"cell_type":"markdown","id":"5b53d22b-e877-44a4-9d1f-32cea6e99fec","metadata":{},"outputs":[],"source":["We'll need the following libraries\n"]},{"cell_type":"code","id":"ba2c87cc-2055-422d-ba92-97e8b9e411c2","metadata":{},"outputs":[],"source":["# Import the libraries we need for this lab\n\n# Using the following line code to install the torchvision library\n# !mamba install -y torchvision\n\nimport torch \nimport torch.nn as nn\nimport torchvision.transforms as transforms\nimport torchvision.datasets as dsets\nimport torch.nn.functional as F\nimport matplotlib.pylab as plt\nimport numpy as np"]},{"cell_type":"markdown","id":"80786270-caee-4b4c-96c4-3b26cec371a2","metadata":{},"outputs":[],"source":["Use the following helper functions for plotting the loss: \n"]},{"cell_type":"code","id":"db3f1d09-3012-42fd-b58a-e22b1cf4d989","metadata":{},"outputs":[],"source":["# Define a function to plot accuracy and loss\n\ndef plot_accuracy_loss(training_results): \n    plt.subplot(2, 1, 1)\n    plt.plot(training_results['training_loss'], 'r')\n    plt.ylabel('loss')\n    plt.title('training loss iterations')\n    plt.subplot(2, 1, 2)\n    plt.plot(training_results['validation_accuracy'])\n    plt.ylabel('accuracy')\n    plt.xlabel('epochs')   \n    plt.show()"]},{"cell_type":"markdown","id":"3ba15b06-a9dd-4d09-8d60-7ba835c922f4","metadata":{},"outputs":[],"source":["Use the following function for printing the model parameters: \n"]},{"cell_type":"code","id":"3f570146-31ea-448b-8e63-12e439dba377","metadata":{},"outputs":[],"source":["# Define a function to plot model parameters\n\ndef print_model_parameters(model):\n    count = 0\n    for ele in model.state_dict():\n        count += 1\n        if count % 2 != 0:\n            print (\"The following are the parameters for the layer \", count // 2 + 1)\n        if ele.find(\"bias\") != -1:\n            print(\"The size of bias: \", model.state_dict()[ele].size())\n        else:\n            print(\"The size of weights: \", model.state_dict()[ele].size())"]},{"cell_type":"markdown","id":"1231b724-191d-4571-b2ea-0557cab3deb4","metadata":{},"outputs":[],"source":["Define the neural network module or class: \n"]},{"cell_type":"code","id":"5c4fcaf7-e7bb-4223-bb5f-f25d5b3b4d38","metadata":{},"outputs":[],"source":["# Define a function to display data\n\ndef show_data(data_sample):\n    plt.imshow(data_sample.numpy().reshape(28, 28), cmap='gray')\n    plt.show()"]},{"cell_type":"markdown","id":"f022ca69-eb8d-476b-89ec-84bf8caf34d5","metadata":{},"outputs":[],"source":["\u003c!--Empty Space for separating topics--\u003e\n"]},{"cell_type":"markdown","id":"af70fc9e-dbd9-4b00-901d-6c78399e2f3f","metadata":{},"outputs":[],"source":["\u003ch2 id=\"Model\"\u003eNeural Network Module and Training Function\u003c/h2\u003e \n"]},{"cell_type":"markdown","id":"2f339f71-ae71-4a0d-bddc-5ec4e4a3e89b","metadata":{},"outputs":[],"source":["Define the neural network module or class: \n"]},{"cell_type":"code","id":"76d027b8-e164-466b-b53a-be1fa0d60fdd","metadata":{},"outputs":[],"source":["# Define a Neural Network class\n\nclass Net(nn.Module):\n    \n    # Constructor\n    def __init__(self, D_in, H, D_out):\n        super(Net, self).__init__()\n        self.linear1 = nn.Linear(D_in, H)\n        self.linear2 = nn.Linear(H, D_out)\n\n    # Prediction    \n    def forward(self, x):\n        x = torch.sigmoid(self.linear1(x))  \n        x = self.linear2(x)\n        return x"]},{"cell_type":"markdown","id":"ad4f5e8e-22d0-4b6b-ad47-f61cb792976d","metadata":{},"outputs":[],"source":["Define a function to train the model. In this case, the function returns a Python dictionary to store the training loss and accuracy on the validation data. \n"]},{"cell_type":"code","id":"8a78bb0a-67b8-422e-bfac-dfa02dd07560","metadata":{},"outputs":[],"source":["# Define a training function to train the model\n\ndef train(model, criterion, train_loader, validation_loader, optimizer, epochs=100):\n    i = 0\n    useful_stuff = {'training_loss': [],'validation_accuracy': []}  \n    for epoch in range(epochs):\n        for i, (x, y) in enumerate(train_loader): \n            optimizer.zero_grad()\n            z = model(x.view(-1, 28 * 28))\n            loss = criterion(z, y)\n            loss.backward()\n            optimizer.step()\n             #loss for every iteration\n            useful_stuff['training_loss'].append(loss.data.item())\n        correct = 0\n        for x, y in validation_loader:\n            #validation \n            z = model(x.view(-1, 28 * 28))\n            _, label = torch.max(z, 1)\n            correct += (label == y).sum().item()\n        accuracy = 100 * (correct / len(validation_dataset))\n        useful_stuff['validation_accuracy'].append(accuracy)\n    return useful_stuff"]},{"cell_type":"markdown","id":"92ae42a5-71e7-48b1-89bb-79650f1da354","metadata":{},"outputs":[],"source":["\u003c!--Empty Space for separating topics--\u003e\n"]},{"cell_type":"markdown","id":"e425fb5c-ac6e-4709-b496-c096700bf575","metadata":{},"outputs":[],"source":["\u003ch2 id=\"Makeup_Data\"\u003eMake Some Data\u003c/h2\u003e \n"]},{"cell_type":"markdown","id":"991540da-11e3-473f-9c3f-b2bf7c1170ac","metadata":{},"outputs":[],"source":["Load the training dataset by setting the parameters \u003ccode\u003etrain\u003c/code\u003e to \u003ccode\u003eTrue\u003c/code\u003e and convert it to a tensor by placing a transform object in the argument \u003ccode\u003etransform\u003c/code\u003e.\n"]},{"cell_type":"code","id":"461914e3-c57b-46ad-85d4-2cd151125f6e","metadata":{},"outputs":[],"source":["# Create training dataset\n\ntrain_dataset = dsets.MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())"]},{"cell_type":"markdown","id":"e8939a5a-c16c-4b17-8597-fd79fe8bf62c","metadata":{},"outputs":[],"source":["Load the testing dataset and convert it to a tensor by placing a transform object in the argument \u003ccode\u003etransform\u003c/code\u003e:\n"]},{"cell_type":"code","id":"16dcac26-7c0c-41a6-958a-cf662237dd7d","metadata":{},"outputs":[],"source":["# Create validating dataset\n\nvalidation_dataset = dsets.MNIST(root='./data', download=True, transform=transforms.ToTensor())"]},{"cell_type":"markdown","id":"f0ab843a-500a-4a7a-8671-a572f0730b65","metadata":{},"outputs":[],"source":["Create the criterion function:  \n"]},{"cell_type":"code","id":"caf39820-12da-4a37-b3b3-399287d26a86","metadata":{},"outputs":[],"source":["# Create criterion function\n\ncriterion = nn.CrossEntropyLoss()"]},{"cell_type":"markdown","id":"3d7b63ca-a615-4fea-bbc0-7b56a761ce52","metadata":{},"outputs":[],"source":["Create the training-data loader and the validation-data loader objects: \n"]},{"cell_type":"code","id":"487aba14-3c1f-4510-b3dc-739a8e6189f4","metadata":{},"outputs":[],"source":["# Create data loader for both train dataset and valdiate dataset\n\ntrain_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=2000, shuffle=True)\nvalidation_loader = torch.utils.data.DataLoader(dataset=validation_dataset, batch_size=5000, shuffle=False)"]},{"cell_type":"markdown","id":"92343a57-e073-4861-9e4f-a0482c2d324e","metadata":{},"outputs":[],"source":["\u003c!--Empty Space for separating topics--\u003e\n"]},{"cell_type":"markdown","id":"a52b34d5-5805-4f7d-9836-75e50a17d117","metadata":{},"outputs":[],"source":["\u003ch2 id=\"Train\"\u003eDefine the Neural Network, Optimizer, and Train the Model\u003c/h2\u003e \n"]},{"cell_type":"markdown","id":"1ba1a788-d5d5-4afd-808d-88e3fcee6649","metadata":{},"outputs":[],"source":["Create the model with 100 neurons: \n"]},{"cell_type":"code","id":"550c2c75-1682-4afa-8f9a-98f9013acdad","metadata":{},"outputs":[],"source":["# Create the model with 100 neurons\n\ninput_dim = 28 * 28\nhidden_dim = 100\noutput_dim = 10\n\nmodel = Net(input_dim, hidden_dim, output_dim)"]},{"cell_type":"markdown","id":"ab4d82d5-2de8-4b5e-aafe-30a0775b6e91","metadata":{},"outputs":[],"source":["Print the model parameters: \n"]},{"cell_type":"code","id":"be86dbae-e66f-4dee-81a1-1f0991270dfc","metadata":{},"outputs":[],"source":["# Print the parameters for model\n\nprint_model_parameters(model)"]},{"cell_type":"markdown","id":"72aec926-9e1e-42f0-890c-e0f3cd8a89f1","metadata":{},"outputs":[],"source":["Define the optimizer object with a learning rate of 0.01: \n"]},{"cell_type":"code","id":"5a3f7a5f-b077-4e1f-b1c8-5de12fb61fb8","metadata":{},"outputs":[],"source":["# Set the learning rate and the optimizer\n\nlearning_rate = 0.01\noptimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"]},{"cell_type":"markdown","id":"06c35124-49b1-4429-9e03-f52b414447f6","metadata":{},"outputs":[],"source":["Train the model by using 100 epochs **(this process takes time)**: \n"]},{"cell_type":"code","id":"1ea68af7-b882-4649-9cf2-6fdec144ca9a","metadata":{},"outputs":[],"source":["# Train the model\n\ntraining_results = train(model, criterion, train_loader, validation_loader, optimizer, epochs=30)"]},{"cell_type":"markdown","id":"ead2b4e7-3679-4436-8788-9f5e8c230409","metadata":{},"outputs":[],"source":["\u003c!--Empty Space for separating topics--\u003e\n"]},{"cell_type":"markdown","id":"e8b5d07c-2ad7-4372-8f3f-758b03155308","metadata":{},"outputs":[],"source":["\u003ch2 id=\"Result\"\u003eAnalyze Results\u003c/h2\u003e \n"]},{"cell_type":"markdown","id":"fea9f3a4-aeb5-4e6f-a222-ca032433062a","metadata":{},"outputs":[],"source":["Plot the training total loss or cost for every iteration and plot the training accuracy for every epoch:  \n"]},{"cell_type":"code","id":"27ea41c3-f787-4f3a-b8eb-a3cf56e9df32","metadata":{},"outputs":[],"source":["# Plot the accuracy and loss\n\nplot_accuracy_loss(training_results)"]},{"cell_type":"markdown","id":"d280838e-7a7f-4f04-a6ca-0415cb7304ac","metadata":{},"outputs":[],"source":["Plot the first five misclassified samples:   \n"]},{"cell_type":"code","id":"b242caa1-11f3-405a-9692-1450978dcc32","metadata":{},"outputs":[],"source":["# Plot the first five misclassified samples\n\ncount = 0\nfor x, y in validation_dataset:\n    z = model(x.reshape(-1, 28 * 28))\n    _,yhat = torch.max(z, 1)\n    if yhat != y:\n        show_data(x)\n        count += 1\n    if count \u003e= 5:\n        break"]},{"cell_type":"markdown","id":"128bab7d-33fd-4cb9-8e9e-6fa601ea6988","metadata":{},"outputs":[],"source":["\u003ch3\u003ePractice\u003c/h3\u003e \n"]},{"cell_type":"markdown","id":"1421d604-2e4f-46f2-8b88-ad46691704c4","metadata":{},"outputs":[],"source":["Use \u003ccode\u003enn.Sequential\u003c/code\u003e to build exactly the same model as you just built. Use the function \u003ctrain\u003etrain\u003c/train\u003e to train the model and use the function \u003ccode\u003eplot_accuracy_loss\u003c/code\u003e to see the metrics. Also, try different epoch numbers. \n"]},{"cell_type":"code","id":"95f2528e-cd84-45f8-8f28-bb70f9e7b832","metadata":{},"outputs":[],"source":["# Practice: Use nn.Sequential to build the same model. Use plot_accuracy_loss to print out the accuarcy and loss\n\n# Type your code here"]},{"cell_type":"markdown","id":"dc7d806c-2094-4995-ba77-25d7b31e0da4","metadata":{},"outputs":[],"source":["Double-click \u003cb\u003ehere\u003c/b\u003e for the solution.\n","\n","\u003c!-- \n","input_dim = 28 * 28\n","hidden_dim = 100\n","output_dim = 10\n","\n","model = torch.nn.Sequential(\n","    torch.nn.Linear(input_dim, hidden_dim),\n","    torch.nn.Sigmoid(),\n","    torch.nn.Linear(hidden_dim, output_dim),\n",")\n","learning_rate = 0.01\n","optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n","training_results = train(model, criterion, train_loader, validation_loader, optimizer, epochs = 10)\n","plot_accuracy_loss(training_results)\n","--\u003e\n"]},{"cell_type":"markdown","id":"c6086b71-35f5-4bf0-8220-aed7417c5f85","metadata":{},"outputs":[],"source":["\n","\u003ca href=\"https://dataplatform.cloud.ibm.com/registration/stepone?utm_source=skills_network\u0026utm_content=in_lab_content_link\u0026utm_id=Lab-IBMDeveloperSkillsNetwork-DL0110EN-SkillsNetwork\u0026context=cpdaas\u0026apps=data_science_experience%2Cwatson_machine_learning\"\u003e\u003cimg src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DL0110EN-SkillsNetwork/Template/module%201/images/Watson_Studio.png\"\u003e\u003c/a\u003e\n"]},{"cell_type":"markdown","id":"86394bbc-f866-44fd-8bef-4bbbd3505b13","metadata":{},"outputs":[],"source":["\u003c!--Empty Space for separating topics--\u003e\n"]},{"cell_type":"markdown","id":"00b4ff93-553c-4465-a57a-e60ea0fc2a8b","metadata":{},"outputs":[],"source":["\u003ch2\u003eAbout the Authors:\u003c/h2\u003e \n","\n","\u003ca href=\"https://www.linkedin.com/in/joseph-s-50398b136/\"\u003eJoseph Santarcangelo\u003c/a\u003e has a PhD in Electrical Engineering, his research focused on using machine learning, signal processing, and computer vision to determine how videos impact human cognition. Joseph has been working for IBM since he completed his PhD. \n"]},{"cell_type":"markdown","id":"ff57b7c6-44ef-4733-ad65-7d509bfec139","metadata":{},"outputs":[],"source":["Other contributors: \u003ca href=\"https://www.linkedin.com/in/michelleccarey/\"\u003eMichelle Carey\u003c/a\u003e, \u003ca href=\"www.linkedin.com/in/jiahui-mavis-zhou-a4537814a\"\u003eMavis Zhou\u003c/a\u003e\n"]},{"cell_type":"markdown","id":"28ac88dc-6215-41ec-9618-87e575824826","metadata":{},"outputs":[],"source":["\u003c!--\n","## Change Log\n","\n","|  Date (YYYY-MM-DD) |  Version | Changed By  |  Change Description |\n","|---|---|---|---|\n","| 2020-09-23  | 2.0  | Shubham  |  Migrated Lab to Markdown and added to course repo in GitLab |\n","--\u003e\n"]},{"cell_type":"markdown","id":"ce0482d0-ffb3-4ea3-88d2-595d81789536","metadata":{},"outputs":[],"source":["\u003chr\u003e\n"]},{"cell_type":"markdown","id":"ca86df82-cd28-4c71-9842-21f680a4ce26","metadata":{},"outputs":[],"source":["\n","\n","\n","## \u003ch3 align=\"center\"\u003e \u0026#169; IBM Corporation. All rights reserved. \u003ch3/\u003e\n"]}],"metadata":{"kernelspec":{"display_name":"Python","language":"python","name":"conda-env-python-py"},"language_info":{"name":""}},"nbformat":4,"nbformat_minor":4}