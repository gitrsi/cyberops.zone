{"cells":[{"cell_type":"markdown","id":"3bad7406-8704-4d49-9ced-587ef31bfea9","metadata":{},"outputs":[],"source":["\u003cp style=\"text-align:center\"\u003e\n","    \u003ca href=\"https://skills.network\" target=\"_blank\"\u003e\n","    \u003cimg src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"\u003e\n","    \u003c/a\u003e\n","\u003c/p\u003e\n"]},{"cell_type":"markdown","id":"edb2cdd1-f9fe-4c67-9400-88def739d5f8","metadata":{},"outputs":[],"source":["\u003ch1\u003eDeeper Neural Networks with nn.ModuleList()\u003c/h1\u003e\n"]},{"cell_type":"markdown","id":"37a90084-59f4-42c4-9e5d-fdd13709f513","metadata":{},"outputs":[],"source":["\n","\u003ch3\u003eObjective for this Notebook\u003ch3\u003e    \n","\u003ch5\u003e 1. Create a Deeper Neural Network with \u003ccode\u003enn.ModuleList()\u003c/code\u003e \u003c/b\u003e\u003c/h5\u003e\n","\u003ch5\u003e 2. Train and Validate the Model. \u003c/h5\u003e\n","\n"]},{"cell_type":"markdown","id":"3b4b4507-f50e-4a17-84b5-156161c0e6fc","metadata":{},"outputs":[],"source":["\u003ch2\u003eTable of Contents\u003c/h2\u003e\n","\u003cp\u003eIn this lab, you will create a Deeper Neural Network with \u003ccode\u003enn.ModuleList()\u003c/code\u003e\u003c/p\u003e\n","\n","\u003cul\u003e\n","    \u003cli\u003e\u003ca href=\"#Model\"\u003eNeural Network Module and Function for Training\u003c/a\u003e\u003c/li\u003e\n","    \u003cli\u003e\u003ca href=\"#Train\"\u003eTrain and Validate the Model\u003c/a\u003e\u003c/li\u003e\n","\u003c/ul\u003e\n","\u003cp\u003eEstimated Time Needed: \u003cstrong\u003e25 min\u003c/strong\u003e\u003c/p\u003e\n","\n","\u003chr\u003e\n"]},{"cell_type":"markdown","id":"d60a5ce8-417c-4aa6-a52a-a952429e2118","metadata":{},"outputs":[],"source":["\u003ch2\u003ePreparation\u003c/h2\u003e\n"]},{"cell_type":"markdown","id":"0f1934fb-186d-4be9-bcba-45577c3dae3c","metadata":{},"outputs":[],"source":["We'll need the following libraries\n"]},{"cell_type":"code","id":"4c2897e4-766b-48ae-bdc5-23887834c363","metadata":{},"outputs":[],"source":["# Import the libraries we need for this lab\n\nimport matplotlib.pyplot as plt \nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom matplotlib.colors import ListedColormap\nfrom torch.utils.data import Dataset, DataLoader\n\ntorch.manual_seed(1)"]},{"cell_type":"markdown","id":"80ef0c10-3aae-466a-81b5-d69a466733e0","metadata":{},"outputs":[],"source":["Function used to plot:\n"]},{"cell_type":"code","id":"d8fb7df2-97d5-442c-b34e-27872b453b86","metadata":{},"outputs":[],"source":["# Define the function to plot the diagram\n\ndef plot_decision_regions_3class(model, data_set):\n    cmap_light = ListedColormap(['#FFAAAA', '#AAFFAA', '#00AAFF'])\n    cmap_bold = ListedColormap(['#FF0000', '#00FF00', '#00AAFF'])\n    X = data_set.x.numpy()\n    y = data_set.y.numpy()\n    h = .02\n    x_min, x_max = X[:, 0].min() - 0.1, X[:, 0].max() + 0.1 \n    y_min, y_max = X[:, 1].min() - 0.1, X[:, 1].max() + 0.1 \n    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n    XX = torch.Tensor(np.c_[xx.ravel(), yy.ravel()])\n    _, yhat = torch.max(model(XX), 1)\n    yhat = yhat.numpy().reshape(xx.shape)\n    plt.pcolormesh(xx, yy, yhat, cmap=cmap_light)\n    plt.plot(X[y[:] == 0, 0], X[y[:] == 0, 1], 'ro', label = 'y=0')\n    plt.plot(X[y[:] == 1, 0], X[y[:] == 1, 1], 'go', label = 'y=1')\n    plt.plot(X[y[:] == 2, 0], X[y[:] == 2, 1], 'o', label = 'y=2')\n    plt.title(\"decision region\")\n    plt.legend()"]},{"cell_type":"markdown","id":"722db9c8-47dd-4ef5-8d02-89639e4291c0","metadata":{},"outputs":[],"source":["Create Dataset \u003ccode\u003eClass\u003c/code\u003e\n"]},{"cell_type":"code","id":"699b32c4-ca9a-40c5-bfdf-8fe8a175de80","metadata":{},"outputs":[],"source":["# Create Data Class\n\nclass Data(Dataset):\n    \n    #  modified from: http://cs231n.github.io/neural-networks-case-study/\n    # Constructor\n    def __init__(self, K=3, N=500):\n        D = 2\n        X = np.zeros((N * K, D)) # data matrix (each row = single example)\n        y = np.zeros(N * K, dtype='uint8') # class labels\n        for j in range(K):\n          ix = range(N * j, N * (j + 1))\n          r = np.linspace(0.0, 1, N) # radius\n          t = np.linspace(j * 4, (j + 1) * 4, N) + np.random.randn(N) * 0.2 # theta\n          X[ix] = np.c_[r * np.sin(t), r*np.cos(t)]\n          y[ix] = j\n        self.y = torch.from_numpy(y).type(torch.LongTensor)\n        self.x = torch.from_numpy(X).type(torch.FloatTensor)\n        self.len = y.shape[0]\n    \n    # Getter\n    def __getitem__(self, index):    \n        return self.x[index], self.y[index]\n    \n    # Get Length\n    def __len__(self):\n        return self.len\n    \n    # Plot the diagram\n    def plot_stuff(self):\n        plt.plot(self.x[self.y[:] == 0, 0].numpy(), self.x[self.y[:] == 0, 1].numpy(), 'o', label=\"y = 0\")\n        plt.plot(self.x[self.y[:] == 1, 0].numpy(), self.x[self.y[:] == 1, 1].numpy(), 'ro', label=\"y = 1\")\n        plt.plot(self.x[self.y[:] == 2, 0].numpy(), self.x[self.y[:] == 2, 1].numpy(), 'go', label=\"y = 2\")\n        plt.legend()"]},{"cell_type":"markdown","id":"1f49f58d-d1ac-456a-bbec-2204f1f237a7","metadata":{},"outputs":[],"source":["\u003c!--Empty Space for separating topics--\u003e\n"]},{"cell_type":"markdown","id":"20d5593a-4955-4cb0-857f-c2ce4342df9e","metadata":{},"outputs":[],"source":["\u003ch2 id=\"Model\"\u003eNeural Network Module and Function for Training\u003c/h2\u003e\n"]},{"cell_type":"markdown","id":"47a30a8e-5454-4fcf-8557-7ea0fcf800f9","metadata":{},"outputs":[],"source":["Neural Network Module using \u003ccode\u003eModuleList()\u003c/code\u003e\n"]},{"cell_type":"code","id":"d7395d5d-4541-4e11-9077-5e889c470105","metadata":{},"outputs":[],"source":["# Create Net model class\n\nclass Net(nn.Module):\n    \n    # Constructor\n    def __init__(self, Layers):\n        super(Net, self).__init__()\n        self.hidden = nn.ModuleList()\n        for input_size, output_size in zip(Layers, Layers[1:]):\n            self.hidden.append(nn.Linear(input_size, output_size))\n    \n    # Prediction\n    def forward(self, activation):\n        L = len(self.hidden)\n        for (l, linear_transform) in zip(range(L), self.hidden):\n            if l \u003c L - 1:\n                activation = F.relu(linear_transform(activation))\n            else:\n                activation = linear_transform(activation)\n        return activation"]},{"cell_type":"markdown","id":"fd523d4f-b07b-444e-a25c-ce8f8aeaebde","metadata":{},"outputs":[],"source":["A function used to train. \n"]},{"cell_type":"code","id":"d9398e47-7905-4f5b-8bb6-7ab267bf1727","metadata":{},"outputs":[],"source":["# Define the function for training the model\n\ndef train(data_set, model, criterion, train_loader, optimizer, epochs=100):\n    LOSS = []\n    ACC = []\n    for epoch in range(epochs):\n        for x, y in train_loader:\n            optimizer.zero_grad()\n            yhat = model(x)\n            loss = criterion(yhat, y)\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            LOSS.append(loss.item())\n        ACC.append(accuracy(model, data_set))\n    \n    fig, ax1 = plt.subplots()\n    color = 'tab:red'\n    ax1.plot(LOSS, color = color)\n    ax1.set_xlabel('Iteration', color = color)\n    ax1.set_ylabel('total loss', color = color)\n    ax1.tick_params(axis = 'y', color = color)\n    \n    ax2 = ax1.twinx()  \n    color = 'tab:blue'\n    ax2.set_ylabel('accuracy', color = color)  # we already handled the x-label with ax1\n    ax2.plot(ACC, color = color)\n    ax2.tick_params(axis = 'y', color = color)\n    fig.tight_layout()  # otherwise the right y-label is slightly clipped\n    \n    plt.show()\n    return LOSS"]},{"cell_type":"markdown","id":"86362e72-2018-468f-b8ef-355e4866542f","metadata":{},"outputs":[],"source":["A function used to calculate accuracy \n"]},{"cell_type":"code","id":"e8fbbb1f-d08f-41e6-bda5-4f6cabac9c8e","metadata":{},"outputs":[],"source":["# The function to calculate the accuracy\n\ndef accuracy(model, data_set):\n    _, yhat = torch.max(model(data_set.x), 1)\n    return (yhat == data_set.y).numpy().mean()"]},{"cell_type":"markdown","id":"0f7f3b45-52df-41e8-a5be-86c277208fca","metadata":{},"outputs":[],"source":["\u003c!--Empty Space for separating topics--\u003e\n"]},{"cell_type":"markdown","id":"7cebc02f-4aac-421c-950a-53b1bf158763","metadata":{},"outputs":[],"source":["\u003ch2 id=\"Train\"\u003eTrain and Validate the Model\u003c/h2\u003e\n"]},{"cell_type":"markdown","id":"6d786a8d-2248-40d3-b6f5-3a13a6b047cc","metadata":{},"outputs":[],"source":["Crate a dataset object:\n"]},{"cell_type":"code","id":"8bb7e4ce-0c51-46e3-b4c2-f6c41d6ec579","metadata":{},"outputs":[],"source":["# Create a Dataset object\n\ndata_set = Data()\ndata_set.plot_stuff()\ndata_set.y = data_set.y.view(-1)"]},{"cell_type":"markdown","id":"3f56d1ba-bad8-4f55-b178-be863ee06f74","metadata":{},"outputs":[],"source":["Create a  network to classify three classes with 1 hidden layer with 50 neurons \n"]},{"cell_type":"code","id":"963e4713-641d-4924-b9ba-735e87917355","metadata":{},"outputs":[],"source":["# Train the model with 1 hidden layer with 50 neurons\n\nLayers = [2, 50, 3]\nmodel = Net(Layers)\nlearning_rate = 0.10\noptimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\ntrain_loader = DataLoader(dataset=data_set, batch_size=20)\ncriterion = nn.CrossEntropyLoss()\nLOSS = train(data_set, model, criterion, train_loader, optimizer, epochs=100)\n\nplot_decision_regions_3class(model, data_set)"]},{"cell_type":"markdown","id":"837f6d75-81c1-413e-9d2a-c47d3d39ff10","metadata":{},"outputs":[],"source":["Create a  network to classify three classes with 2 hidden layers with 20 neurons in total \n"]},{"cell_type":"code","id":"80efd056-2b0f-46bd-a1d7-9ace1646f376","metadata":{},"outputs":[],"source":["Net([3,3,4,3]).parameters"]},{"cell_type":"code","id":"c7f5b659-bae6-430c-ad78-927a79a99bcb","metadata":{},"outputs":[],"source":["# Train the model with 2 hidden layers with 20 neurons\n\nLayers = [2, 10, 10, 3]\nmodel = Net(Layers)\nlearning_rate = 0.01\noptimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\ntrain_loader = DataLoader(dataset=data_set, batch_size=20)\ncriterion = nn.CrossEntropyLoss()\nLOSS = train(data_set, model, criterion, train_loader, optimizer, epochs=1000)\n\nplot_decision_regions_3class(model, data_set)"]},{"cell_type":"markdown","id":"3b5cf99a-1033-4661-b02c-33930fdbdd03","metadata":{},"outputs":[],"source":["\u003ch3\u003ePractice\u003c/h3\u003e\n"]},{"cell_type":"markdown","id":"9f70bd78-badb-43ac-84bd-ed59bea3adb8","metadata":{},"outputs":[],"source":["Create a network with three hidden layers each with ten neurons, then train the network using the same process as above \n"]},{"cell_type":"code","id":"31d1ca33-66ac-4390-bcad-bda8b0193a6a","metadata":{},"outputs":[],"source":["# Practice: Create a network with three hidden layers each with ten neurons.\n\n# Type your code here"]},{"cell_type":"markdown","id":"5b892f02-2406-4f82-bd55-48aff74b78f4","metadata":{},"outputs":[],"source":["Double-click \u003cb\u003ehere\u003c/b\u003e for the solution.\n","\n","\u003c!-- \n","Layers = [2, 10, 10, 10, 3]\n","model = Net(Layers)\n","learning_rate = 0.01\n","optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n","train_loader = DataLoader(dataset = data_set, batch_size = 20)\n","criterion = nn.CrossEntropyLoss()\n","LOSS = train(data_set, model, criterion, train_loader, optimizer, epochs = 1000)\n","plot_decision_regions_3class(model, data_set)\n","--\u003e\n"]},{"cell_type":"markdown","id":"a672b91a-0e9b-4cc3-bd34-b596be384286","metadata":{},"outputs":[],"source":["\n","\n","\u003ca href=\"https://dataplatform.cloud.ibm.com/registration/stepone?utm_source=skills_network\u0026utm_content=in_lab_content_link\u0026utm_id=Lab-IBMDeveloperSkillsNetwork-DL0110EN-SkillsNetwork\u0026context=cpdaas\u0026apps=data_science_experience%2Cwatson_machine_learning\"\u003e\u003cimg src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DL0110EN-SkillsNetwork/Template/module%201/images/Watson_Studio.png\"\u003e\u003c/a\u003e\n"]},{"cell_type":"markdown","id":"43c4b6fe-c02c-455e-9d5a-7b7961e1652c","metadata":{},"outputs":[],"source":["\u003c!--Empty Space for separating topics--\u003e\n"]},{"cell_type":"markdown","id":"7e2640f3-4ebc-4d11-bb6e-d57a564f062c","metadata":{},"outputs":[],"source":["\u003ch2\u003eAbout the Authors:\u003c/h2\u003e \n","\n","\u003ca href=\"https://www.linkedin.com/in/joseph-s-50398b136/\"\u003eJoseph Santarcangelo\u003c/a\u003e has a PhD in Electrical Engineering, his research focused on using machine learning, signal processing, and computer vision to determine how videos impact human cognition. Joseph has been working for IBM since he completed his PhD. \n"]},{"cell_type":"markdown","id":"d99b8f54-5572-4236-bdd0-dea84447f0e9","metadata":{},"outputs":[],"source":["Other contributors: \u003ca href=\"https://www.linkedin.com/in/michelleccarey/\"\u003eMichelle Carey\u003c/a\u003e, \u003ca href=\"www.linkedin.com/in/jiahui-mavis-zhou-a4537814a\"\u003eMavis Zhou\u003c/a\u003e\n"]},{"cell_type":"markdown","id":"c768f73d-9c1b-467b-ae74-1c50f13f0882","metadata":{},"outputs":[],"source":["\u003c!--\n","## Change Log\n","\n","|  Date (YYYY-MM-DD) |  Version | Changed By  |  Change Description |\n","|---|---|---|---|\n","| 2020-09-21  | 2.0  | Srishti  |  Migrated Lab to Markdown and added to course repo in GitLab |\n","\n","\n","\n","\u003chr\u003e\n","--\u003e\n","\n","## \u003ch3 align=\"center\"\u003e \u0026#169; IBM Corporation. All rights reserved. \u003ch3/\u003e\n"]}],"metadata":{"kernelspec":{"display_name":"Python","language":"python","name":"conda-env-python-py"},"language_info":{"name":""}},"nbformat":4,"nbformat_minor":4}